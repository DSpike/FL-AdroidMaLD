{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the original dataset: 125\n",
      "GA-PSO Fitness: 0.9598275079437131\n",
      "ACO-SA Fitness: 0.8935542442124376\n",
      "Final Model Accuracy with Combined Features: 0.9620971402632773\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import Random Forest\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV files with 'after_reboot' in the filename\n",
    "path = r'C:\\Users\\USER\\Documents\\NTUST\\Conference_Workshop_Seminar\\Android\\Dataset\\AndMal2020-dynamic-BeforeAndAfterReboot\\Cleaned_Files\\normalized_dataset'\n",
    "files = glob.glob(path + '/*after_reboot*.csv')\n",
    "\n",
    "dataframes = []\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    features = df.drop(columns=['Category', 'Family'])\n",
    "    dataframes.append(features)\n",
    "    labels.append(df['Category'])\n",
    "\n",
    "# Combine all feature dataframes\n",
    "X = pd.concat(dataframes, ignore_index=True)\n",
    "y = pd.concat(labels, ignore_index=True)\n",
    "\n",
    "# Print the number of features in the original dataset\n",
    "num_features = X.shape[1]\n",
    "print(f'Number of features in the original dataset: {num_features}')\n",
    "\n",
    "# Impute missing values first\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_imputed = imp.fit_transform(X)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame for feature selection\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "### Function to Evaluate Random Forest Performance ###\n",
    "def evaluate_random_forest(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    model = RandomForestClassifier()  # Changed to Random Forest\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    predictions = model.predict(X_test_pca)\n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "### Feature Extraction Algorithms ###\n",
    "def ga_pso(X, y):\n",
    "    # Placeholder for GA-PSO feature selection logic\n",
    "    selected_features = X.sample(n=90, axis=1)  # Randomly select 90 features for demonstration\n",
    "    fitness = evaluate_random_forest(selected_features, y)\n",
    "    return selected_features, fitness\n",
    "\n",
    "def aco_sa(X, y):\n",
    "    # Placeholder for ACO-SA feature selection logic\n",
    "    selected_features = X.iloc[:, 65:85]  # Select features from index 65 to 85 for demonstration\n",
    "    fitness = evaluate_random_forest(selected_features, y)\n",
    "    return selected_features, fitness\n",
    "\n",
    "# Extract features using optimization methods\n",
    "features_ga_pso, fitness_ga_pso = ga_pso(X_imputed_df, y)\n",
    "features_aco_sa, fitness_aco_sa = aco_sa(X_imputed_df, y)\n",
    "\n",
    "# Print fitness scores for individual algorithms\n",
    "print(f'GA-PSO Fitness: {fitness_ga_pso}')\n",
    "print(f'ACO-SA Fitness: {fitness_aco_sa}')\n",
    "\n",
    "# Combine unique features from both methods\n",
    "combined_features = pd.concat([features_ga_pso, features_aco_sa], axis=1).loc[:, ~pd.concat([features_ga_pso, features_aco_sa], axis=1).columns.duplicated()]\n",
    "\n",
    "# Evaluate the model on combined features\n",
    "final_fitness_combined = evaluate_random_forest(combined_features, y)\n",
    "print(f'Final Model Accuracy with Combined Features: {final_fitness_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the original dataset: 125\n",
      "GA-PSO Fitness: 0.9652746255106672\n",
      "ACO-SA Fitness: 0.880390376758965\n",
      "Final Model Accuracy with Combined Features: 0.9652746255106672\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV files with 'after_reboot' in the filename\n",
    "path = r'C:\\Users\\USER\\Documents\\NTUST\\Conference_Workshop_Seminar\\Android\\Dataset\\AndMal2020-dynamic-BeforeAndAfterReboot\\Cleaned_Files\\normalized_dataset'\n",
    "files = glob.glob(path + '/*after_reboot*.csv')\n",
    "\n",
    "dataframes = []\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    features = df.drop(columns=['Category', 'Family'])\n",
    "    dataframes.append(features)\n",
    "    labels.append(df['Category'])\n",
    "\n",
    "# Combine all feature dataframes\n",
    "X = pd.concat(dataframes, ignore_index=True)\n",
    "y = pd.concat(labels, ignore_index=True)\n",
    "\n",
    "# Print the number of features in the original dataset\n",
    "num_features = X.shape[1]\n",
    "print(f'Number of features in the original dataset: {num_features}')\n",
    "\n",
    "# Impute missing values first\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_imputed = imp.fit_transform(X)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame for feature selection\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "### Function to Evaluate Random Forest Performance ###\n",
    "def evaluate_random_forest(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "    X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train_pca, y_train_resampled)\n",
    "    predictions = model.predict(X_test_pca)\n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "### Feature Extraction Algorithms ###\n",
    "def ga_pso(X, y):\n",
    "    # Placeholder for GA-PSO feature selection logic\n",
    "    selected_features = X.sample(n=95, axis=1)  # Randomly select 90 features for demonstration\n",
    "    fitness = evaluate_random_forest(selected_features, y)\n",
    "    return selected_features, fitness\n",
    "\n",
    "def aco_sa(X, y):\n",
    "    # Placeholder for ACO-SA feature selection logic\n",
    "    selected_features = X.iloc[:, 65:85]  # Select features from index 65 to 85 for demonstration\n",
    "    fitness = evaluate_random_forest(selected_features, y)\n",
    "    return selected_features, fitness\n",
    "\n",
    "# Extract features using optimization methods\n",
    "features_ga_pso, fitness_ga_pso = ga_pso(X_imputed_df, y)\n",
    "features_aco_sa, fitness_aco_sa = aco_sa(X_imputed_df, y)\n",
    "\n",
    "# Print fitness scores for individual algorithms\n",
    "print(f'GA-PSO Fitness: {fitness_ga_pso}')\n",
    "print(f'ACO-SA Fitness: {fitness_aco_sa}')\n",
    "\n",
    "# Combine unique features from both methods\n",
    "combined_features = pd.concat([features_ga_pso, features_aco_sa], axis=1).loc[:, ~pd.concat([features_ga_pso, features_aco_sa], axis=1).columns.duplicated()]\n",
    "\n",
    "# Evaluate the model on combined features\n",
    "final_fitness_combined = evaluate_random_forest(combined_features, y)\n",
    "print(f'Final Model Accuracy with Combined Features: {final_fitness_combined}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA-PSO Fitness: 0.9825238311393554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV files with 'after_reboot' in the filename\n",
    "path = r'C:\\Users\\USER\\Documents\\NTUST\\Conference_Workshop_Seminar\\Android\\Dataset\\AndMal2020-dynamic-BeforeAndAfterReboot\\Cleaned_Files\\normalized_dataset'\n",
    "files = glob.glob(path + '/*after_reboot*.csv')\n",
    "\n",
    "dataframes = []\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    features = df.drop(columns=['Category', 'Family'])\n",
    "    dataframes.append(features)\n",
    "    labels.append(df['Category'])\n",
    "\n",
    "# Combine all feature dataframes\n",
    "X = pd.concat(dataframes, ignore_index=True)\n",
    "y = pd.concat(labels, ignore_index=True)\n",
    "\n",
    "# Impute missing values first\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_imputed = imp.fit_transform(X)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame for feature selection\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "### Function to Evaluate Ensemble Method Performance ###\n",
    "def evaluate_ensemble(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Apply PCA with fewer components\n",
    "    pca = PCA(n_components=0.85)  # Retain 85% of variance\n",
    "    X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Define classifiers\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    lr = LogisticRegression(max_iter=100, random_state=42)\n",
    "\n",
    "    # Hyperparameter tuning for each classifier\n",
    "    param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}  # Expanded grid\n",
    "    param_grid_rf = {'n_estimators': [50, 100, 200]}  # Expanded grid\n",
    "    param_grid_lr = {'C': [0.1, 1, 10]}  # Expanded grid\n",
    "\n",
    "    # Perform GridSearchCV for each classifier\n",
    "    svm_grid = GridSearchCV(svm, param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    rf_grid = GridSearchCV(rf, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    lr_grid = GridSearchCV(lr, param_grid_lr, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV models\n",
    "    svm_grid.fit(X_train_pca, y_train_resampled)\n",
    "    rf_grid.fit(X_train_pca, y_train_resampled)\n",
    "    lr_grid.fit(X_train_pca, y_train_resampled)\n",
    "\n",
    "    # Get the best estimators\n",
    "    best_svm = svm_grid.best_estimator_\n",
    "    best_rf = rf_grid.best_estimator_\n",
    "    best_lr = lr_grid.best_estimator_\n",
    "\n",
    "    # Create the ensemble model with the best estimators\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', best_svm),\n",
    "            ('rf', best_rf),\n",
    "            ('lr', best_lr)\n",
    "        ],\n",
    "        voting='soft',  # Use 'soft' voting for probability-based voting\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the ensemble model\n",
    "    ensemble_model.fit(X_train_pca, y_train_resampled)\n",
    "    predictions = ensemble_model.predict(X_test_pca)\n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "### GA-PSO Feature Selection Algorithm ###\n",
    "def ga_pso(X, y):\n",
    "    # Use SelectKBest for efficient feature selection\n",
    "    selector = SelectKBest(score_func=f_classif, k=95)  # Select top 95 features\n",
    "    selected_features = selector.fit_transform(X, y)\n",
    "    selected_feature_names = X.columns[selector.get_support()]\n",
    "    selected_features_df = pd.DataFrame(selected_features, columns=selected_feature_names)\n",
    "\n",
    "    # Evaluate the ensemble model on selected features\n",
    "    fitness = evaluate_ensemble(selected_features_df, y)\n",
    "    return selected_features_df, fitness\n",
    "\n",
    "# Extract features using GA-PSO and evaluate the ensemble model\n",
    "features_ga_pso, fitness_ga_pso = ga_pso(X_imputed_df, y)\n",
    "\n",
    "# Print fitness score for GA-PSO\n",
    "print(f'GA-PSO Fitness: {fitness_ga_pso}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV files with 'after_reboot' in the filename\n",
    "path = r'C:\\Users\\USER\\Documents\\NTUST\\Conference_Workshop_Seminar\\Android\\Dataset\\AndMal2020-dynamic-BeforeAndAfterReboot\\Cleaned_Files\\normalized_dataset'\n",
    "files = glob.glob(path + '/*after_reboot*.csv')\n",
    "\n",
    "dataframes = []\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    features = df.drop(columns=['Category', 'Family'])\n",
    "    dataframes.append(features)\n",
    "    labels.append(df['Category'])\n",
    "\n",
    "# Combine all feature dataframes\n",
    "X = pd.concat(dataframes, ignore_index=True)\n",
    "y = pd.concat(labels, ignore_index=True)\n",
    "\n",
    "# Impute missing values first\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_imputed = imp.fit_transform(X)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame for feature selection\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "### Function to Evaluate Ensemble Method Performance ###\n",
    "def evaluate_ensemble(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Apply PCA with fewer components\n",
    "    pca = PCA(n_components=0.85)  # Retain 85% of variance\n",
    "    X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Define classifiers\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    lr = LogisticRegression(max_iter=100, random_state=42)\n",
    "\n",
    "    # Hyperparameter tuning for each classifier\n",
    "    param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "    param_grid_rf = {'n_estimators': [50, 100, 200]}\n",
    "    param_grid_lr = {'C': [0.1, 1, 10]}\n",
    "\n",
    "    # Perform GridSearchCV for each classifier\n",
    "    svm_grid = GridSearchCV(svm, param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    rf_grid = GridSearchCV(rf, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    lr_grid = GridSearchCV(lr, param_grid_lr, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV models\n",
    "    svm_grid.fit(X_train_pca, y_train_resampled)\n",
    "    rf_grid.fit(X_train_pca, y_train_resampled)\n",
    "    lr_grid.fit(X_train_pca, y_train_resampled)\n",
    "\n",
    "    # Get the best estimators\n",
    "    best_svm = svm_grid.best_estimator_\n",
    "    best_rf = rf_grid.best_estimator_\n",
    "    best_lr = lr_grid.best_estimator_\n",
    "\n",
    "    # Create the ensemble model with the best estimators\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', best_svm),\n",
    "            ('rf', best_rf),\n",
    "            ('lr', best_lr)\n",
    "        ],\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the ensemble model\n",
    "    ensemble_model.fit(X_train_pca, y_train_resampled)\n",
    "    predictions = ensemble_model.predict(X_test_pca)\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "### GA-PSO Feature Selection Algorithm ###\n",
    "def ga_pso(X, y):\n",
    "    # Use SelectKBest for efficient feature selection\n",
    "    selector = SelectKBest(score_func=f_classif, k=95)  # Select top 95 features\n",
    "    selected_features = selector.fit_transform(X, y)\n",
    "    selected_feature_names = X.columns[selector.get_support()]\n",
    "    selected_features_df = pd.DataFrame(selected_features, columns=selected_feature_names)\n",
    "\n",
    "    # Evaluate the ensemble model on selected features\n",
    "    fitness = evaluate_ensemble(selected_features_df, y)\n",
    "    return selected_features_df, fitness\n",
    "\n",
    "# Extract features using GA-PSO and evaluate the ensemble model\n",
    "features_ga_pso, fitness_ga_pso = ga_pso(X_imputed_df, y)\n",
    "\n",
    "# Print fitness score for GA-PSO\n",
    "print(f'GA-PSO Fitness: {fitness_ga_pso}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files with 'after_reboot' in the filename\n",
    "path = r'C:\\Users\\USER\\Documents\\NTUST\\Conference_Workshop_Seminar\\Android\\Dataset\\AndMal2020-dynamic-BeforeAndAfterReboot\\Cleaned_Files\\normalized_dataset'\n",
    "files = glob.glob(path + '/*after_reboot*.csv')\n",
    "\n",
    "dataframes = []\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    features = df.drop(columns=['Category', 'Family'])\n",
    "    dataframes.append(features)\n",
    "    labels.append(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine all feature dataframes\n",
    "X = pd.concat(dataframes, ignore_index=True)\n",
    "y = pd.concat(labels, ignore_index=True)\n",
    "\n",
    "# Impute missing values first\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_imputed = imp.fit_transform(X)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame for feature selection\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Adware       0.99      0.99      0.99      1018\n",
      "      Backdoor       0.98      0.93      0.95       109\n",
      "  FileInfector       1.00      0.91      0.95        22\n",
      "           PUA       0.97      0.97      0.97       155\n",
      "    Ransomware       0.98      0.99      0.99       311\n",
      "      Riskware       0.99      0.99      0.99      1368\n",
      "     Scareware       0.97      0.96      0.97        81\n",
      "        Trojan       0.99      0.99      0.99       791\n",
      " Trojan_Banker       0.91      0.81      0.86        26\n",
      "Trojan_Dropper       0.95      0.95      0.95       151\n",
      "    Trojan_SMS       0.96      0.98      0.97       181\n",
      "    Trojan_Spy       0.98      0.98      0.98       193\n",
      "\n",
      "      accuracy                           0.98      4406\n",
      "     macro avg       0.97      0.95      0.96      4406\n",
      "  weighted avg       0.98      0.98      0.98      4406\n",
      "\n",
      "GA-PSO Fitness: 0.9843395369950068\n"
     ]
    }
   ],
   "source": [
    "### Function to Evaluate SVM Performance ###\n",
    "def evaluate_svm(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Apply PCA with fewer components\n",
    "    pca = PCA(n_components=0.85)  # Retain 85% of variance\n",
    "    X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Define the SVM classifier\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "    # Hyperparameter tuning for SVM\n",
    "    param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "    svm_grid = GridSearchCV(svm, param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV model\n",
    "    svm_grid.fit(X_train_pca, y_train_resampled)\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_svm = svm_grid.best_estimator_\n",
    "\n",
    "    # Fit the best SVM model and make predictions\n",
    "    best_svm.fit(X_train_pca, y_train_resampled)\n",
    "    predictions = best_svm.predict(X_test_pca)\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "### GA-PSO Feature Selection Algorithm ###\n",
    "def ga_pso(X, y):\n",
    "    # Use SelectKBest for efficient feature selection\n",
    "    selector = SelectKBest(score_func=f_classif, k=95)  # Select top 95 features\n",
    "    selected_features = selector.fit_transform(X, y)\n",
    "    selected_feature_names = X.columns[selector.get_support()]\n",
    "    selected_features_df = pd.DataFrame(selected_features, columns=selected_feature_names)\n",
    "\n",
    "    # Evaluate the SVM model on selected features\n",
    "    fitness = evaluate_svm(selected_features_df, y)\n",
    "    return selected_features_df, fitness\n",
    "\n",
    "# Extract features using GA-PSO and evaluate the SVM model\n",
    "features_ga_pso, fitness_ga_pso = ga_pso(X_imputed_df, y)\n",
    "\n",
    "# Print fitness score for GA-PSO\n",
    "print(f'GA-PSO Fitness: {fitness_ga_pso}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
